{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASO REAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#import time\n",
    "#timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "#filename = \"data_anonymized\"\n",
    "#file = \"data/\"+  filename + \".csv\"\n",
    "#df = pd.read_csv(file,index_col=0, parse_dates=['Fecha'])\n",
    "\n",
    "# Limpiamos los datos y realizamos comprobaciones\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agrupar y crear la time series\n",
    "Agrupamos semanalmente y construimos una serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts = pd.Series(df[\"PesoNeto\"].values, index=df.index)\n",
    "#ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "#from matplotlib import pyplot\n",
    "#series = ts\n",
    "#result = seasonal_decompose(series, model='additive')\n",
    "#f = result.plot()\n",
    "#pyplot.show()\n",
    "#f.savefig(\"results/ARIMA/\" + \"_file:\" + filename + \"_\" + timestr + \"_Decomposition.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir entre Train y Test.\n",
    "Train a su vez se dividiran en subtrain y subvalidation ya que utilizamos Cross Validation\n",
    "Test nos servirá para hacer una simulación final de que estamos haciendo bien las predicciones\n",
    "La métrica que se minimiza del error es la correspondiente a Cross Validation. Posteriormente podemos compararla con la métrica del Test, deberían ser parecidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#import matplotlib.pyplot as plt\n",
    "#import numpy\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(ts, ts, test_size=0.26, shuffle=False)\n",
    "\n",
    "# De momento trabajamos sin variables regresoras así que vamos a trabajar unicamente con y_train y y_test\n",
    "#plt.plot(Y_train)\n",
    "#plt.plot(Y_train[-1::].append(Y_test))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar el modelo con los parametros obtenidos en CV\n",
    "Se entrena el modelo con los parametors optimizados de CV y se hacen predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import TimeSeriesSplit\n",
    "#import statsmodels.api as sm\n",
    "\n",
    "# Introducir aqui los parametros ya tuneados\n",
    "#order = (1, 0, 1)\n",
    "#seasonal_order = (0,1,0,53)\n",
    "#enforce_stationarity = True\n",
    "#enforce_invertibility = True\n",
    "#h=1\n",
    "# trend='t'\n",
    "\n",
    "#Rollingts = Y_train\n",
    "#yhat = []\n",
    "#yhatvalue = []\n",
    "#\n",
    "#for index in range(len(Y_test[0::])+1-h):\n",
    "#    print(len(Y_test[0::])+1-h - index)\n",
    "#    modelo_test = sm.tsa.statespace.SARIMAX(Rollingts, order = order, seasonal_order = seasonal_order,\n",
    "#                                            trend='t', enforce_stationarity=enforce_stationarity,\n",
    "#                                            enforce_invertibility=enforce_invertibility)       \n",
    "#    model_fit = modelo_test.fit()\n",
    "#    valforecast = model_fit.forecast(h)\n",
    "#    #print(valforecast)\n",
    "#    if len(yhat) == 0:\n",
    "#        yhat = valforecast[-1::]\n",
    "#    else:\n",
    "#        yhat = yhat.append(valforecast[-1::])\n",
    "\n",
    "#    Rollingts = Rollingts.append(Y_test[index:index+1])\n",
    "\n",
    "\n",
    "#plt.plot(Y_test[h-1:len(yhat)])\n",
    "#plt.plot(yhat)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## VARIABLES\n",
    "# FIGURE TRAIN TEST\n",
    "#ftraintest, axtraintest = plt.subplots(figsize = [12,8]) # no visible frame\n",
    "#df_modelo = Y_test[h-1:]\n",
    "#axtraintest.plot(Y_test[h-1:len(yhat)], 'b', label= \"real\",lw=6)\n",
    "#axtraintest.plot(yhat,'g',label= \"prediction\", lw=5)\n",
    "#axtraintest.legend()\n",
    "#ftraintest.savefig(\"results/ARIMA/h\" + str(h)+ \"/Hyperparameter_ARIMA_h:\" + str(h) +\n",
    "#                    \"_file:\" + filename + \"_\" + timestr + \"_PREDICTIONfig.pdf\")\n",
    "\n",
    "###########################################################\n",
    "#SAVE SERIES #############################################\n",
    "###########################################################\n",
    "#df_modelo = pd.merge(pd.DataFrame(Y_test[h-1:]), pd.DataFrame(yhat), left_index=True, right_index=True)\n",
    "#df_modelo.columns = [\"real\", \"forecast\"]\n",
    "#df_modelo.to_csv(\"results/ARIMA/h\" + str(h) + \"/Hyperparameter_ARIMA_h:\" + str(h) + \"_file:\" +\n",
    "#                  filename + \"_\" +   timestr + \"PREDICCION.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#umbral = max(df_modelo[\"real\"])/10\n",
    "#import numpy as np\n",
    "#df_modelo_mod = df_modelo[df_modelo[\"real\"] > umbral]\n",
    "# Error medio quitando un extremo\n",
    "# Error medio cometido\n",
    "\n",
    "#with open(\"results/ARIMA/h\" + str(h) + \"/Hyperparameter_ARIMA_h:\" + str(h) + \"_file:\" +\n",
    "#          filename + \"_\" + timestr + \"ERRORS.csv\", 'w') as file:\n",
    "#    print(\"Error medio cometido (quitando minimos): \" + str(round(np.mean(abs(df_modelo_mod[\"forecast\"] - df_modelo_mod[\"real\"])/df_modelo_mod[\"real\"]), 3)), file=file)\n",
    "#    print(\"Error medio cometido: \" + str(round(np.mean(abs(df_modelo[\"forecast\"] - df_modelo[\"real\"])/df_modelo[\"real\"]), 3)), file=file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
